{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DC_2_Learn_MNIST_Classifiers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7ZNMQ0Fjpwda+XA8voyaX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/squeeko/DeepChem_projects/blob/master/DC_2_Learn_MNIST_Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWRY9gb-xAF3",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial Part 2: Learning MNIST Digit Classifiers\n",
        "\n",
        "In the previous tutorial, we learned some basics of how to load data into DeepChem and how to use the basic DeepChem objects to load and manipulate this data. In this tutorial, you'll put the parts together and learn how to train a basic image classification model in DeepChem. You might ask, why are we bothering to learn this material in DeepChem? Part of the reason is that image processing is an increasingly important part of AI for the life sciences. So learning how to train image processing models will be very useful for using some of the more advanced DeepChem features.\n",
        "\n",
        "The MNIST dataset contains handwritten digits along with their human annotated labels. The learning challenge for this dataset is to train a model that maps the digit image to its true label. MNIST has been a standard benchmark for machine learning for decades at this point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MGiXOitwzzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c8e7f2ee-dd2a-4c66-ae64-b96b9ebcf5eb"
      },
      "source": [
        "# As always we need to run the setup in working in Google Colab!\n",
        "\n",
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "import conda_installer\n",
        "conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3490  100  3490    0     0  18368      0 --:--:-- --:--:-- --:--:-- 18465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.6/site-packages to PYTHONPATH\n",
            "python version: 3.6.9\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit, openmm, pdbfixer\n",
            "added omnia to channels\n",
            "added conda-forge to channels\n",
            "done\n",
            "conda packages installation finished!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /root/miniconda\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMiSz3BWxq4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "2b26d821-a661-4e3f-8ca8-0b2696a63301"
      },
      "source": [
        "!pip install --pre deepchem\n",
        "import deepchem\n",
        "deepchem.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepchem\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/23/51a96cba097428794e3864a4c969f2c4f27f450a9c074cd3f69aecd87169/deepchem-2.4.0rc1.dev20200921195626.tar.gz (390kB)\n",
            "\r\u001b[K     |▉                               | 10kB 29.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 92kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 133kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 143kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 153kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 163kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 174kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 184kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 194kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 204kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 215kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 225kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 235kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 245kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 256kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 266kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 276kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 286kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 296kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 307kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 317kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 327kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 337kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 348kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 358kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 368kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 378kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 389kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 399kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from deepchem) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->deepchem) (1.15.0)\n",
            "Building wheels for collected packages: deepchem\n",
            "  Building wheel for deepchem (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepchem: filename=deepchem-2.4.0rc1.dev20200921225050-cp36-none-any.whl size=495598 sha256=25dec4065844122fddb95815223a90a10cb4a08335f04cd2564121d5cf79c9db\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/a6/b4/ba3ded5d5350c268f459a51638e265939b9ab601f1ce3e9732\n",
            "Successfully built deepchem\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.4.0rc1.dev20200921225050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0-rc1.dev'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6Q8fpz4yQz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import deepchem as dc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Reshape, Conv2D, Flatten, Dense"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeeY9C3Yynyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
        "train_images = mnist[0][0].reshape((-1, 28, 28, 1)) / 255\n",
        "valid_images = mnist[1][0].reshape((-1, 28, 28, 1)) / 255\n",
        "train = dc.data.NumpyDataset(train_images, mnist[0][1])\n",
        "valid = dc.data.NumpyDataset(valid_images, mnist[1][1])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IImBSvukzYxV",
        "colab_type": "text"
      },
      "source": [
        "Now create the model. We use two convolutional layers followed by two dense layers. The final layer outputs ten numbers for each sample. These correspond to the ten possible digits.\n",
        "\n",
        "How does the model know how to interpret the output? That is determined by the loss function. We specify SparseSoftmaxCrossEntropy. This is a very convenient class that implements a common case:\n",
        "\n",
        "\n",
        "\n",
        "1.   Each label is an integer which is interpreted as a class index (i.e. which of the ten digits this sample is a drawing of).\n",
        "\n",
        "2.   The outputs are passed through a softmax function, and the result is interpreted as a probability distribution over those same classes.\n",
        "\n",
        "The model learns to produce a large output for the correct class, and small outputs for all other classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg-q_IKkzVP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras_model = tf.keras.Sequential([\n",
        "                                   Conv2D(filters=32, kernel_size=5, activation=tf.nn.relu),\n",
        "                                   Conv2D(filters=64, kernel_size=5, activation=tf.nn.relu),\n",
        "                                   Flatten(),\n",
        "                                   Dense(1024, activation=tf.nn.relu),\n",
        "                                   Dense(10),\n",
        "\n",
        "])\n",
        "\n",
        "model = dc.models.KerasModel(keras_model, dc.models.losses.SparseSoftmaxCrossEntropy())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39IfP1sk1rOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ce59b96-c02f-4fbe-93e6-8c53f492a3c9"
      },
      "source": [
        "model.fit(train, nb_epoch=2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02732362985610962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7czfZ4O3bme",
        "colab_type": "text"
      },
      "source": [
        "Let's see how well it works. We ask the model to predict the class of every sample in the validation set. Remember there are ten outputs for each sample. We use argmax() to identify the largest one, which corresponds to the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5NBuwrR12gP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f623cc3b-1c06-4040-fa80-72fbbcc0429f"
      },
      "source": [
        "prediction = np.argmax(model.predict_on_batch(valid.X), axis=1)\n",
        "score = dc.metrics.accuracy_score(prediction, valid.y)\n",
        "print('Validation set accuracy', score)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation set accuracy 0.9892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usmQlmvZ4GBd",
        "colab_type": "text"
      },
      "source": [
        "It gets about 99% of samples correct. Not too bad for such a simple model!\n",
        "\n"
      ]
    }
  ]
}